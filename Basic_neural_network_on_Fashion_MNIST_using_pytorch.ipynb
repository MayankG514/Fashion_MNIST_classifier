{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic neural network on Fashion_MNIST using pytorch",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pZgVWUgm8RC",
        "colab_type": "text"
      },
      "source": [
        "## Importing necessary modules \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUNrEN91hEiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2caxNmBV_cre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAOmBzwwT8Y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNkA_WFknCSO",
        "colab_type": "text"
      },
      "source": [
        "## Extracting FashionMNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlMlJ3n0DBLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=torchvision.datasets.FashionMNIST(\"./data\",download=True,transform=torchvision.transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48cr_B-PG5iR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "6998dba1-03dd-4e16-d738-a402ab0070de"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hp7_47SHR41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data=torchvision.datasets.FashionMNIST(\"/.data\",download=True,train=False,transform=torchvision.transforms.Compose([transforms.ToTensor()]))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpNToOWlHtvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "9d0404d5-4fb8-4cc6-d5a9-2e95ae973c15"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset FashionMNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMXFZbmfnJUG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8URiGiafU6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 5\n",
        "count = 0\n",
        "# Lists for visualization of loss and accuracy \n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRvwl2n0fbjm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions_list = []\n",
        "labels_list = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7YMY4UVhakk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our data\n",
        "train_loader = torch.utils.data.DataLoader(train_data, \n",
        "                                           batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=100)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbR6UMY5iGuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b02a7f60-27bb-45c0-9a0c-161397a661ed"
      },
      "source": [
        "train_loader"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f89ef086278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnWnm7Rjnr4V",
        "colab_type": "text"
      },
      "source": [
        "###We have 10 types of clothes in FashionMNIST dataset.\n",
        "####Making a method that return the name of class for the label number. ex. if the label is 5, we return Sandal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kW1gqg-ilyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_label(label):\n",
        "  output_mapping = {\n",
        "      0: \"T-shirt/Top\",\n",
        "      1: \"Trouser\",\n",
        "      2: \"Pullover\",\n",
        "      3: \"Dress\",\n",
        "      4: \"Coat\", \n",
        "      5: \"Sandal\", \n",
        "      6: \"Shirt\",\n",
        "      7: \"Sneaker\",\n",
        "      8: \"Bag\",\n",
        "      9: \"Ankle Boot\"}\n",
        "  input = (label.item() if type(label) == torch.Tensor else label)\n",
        "  return output_mapping[input]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d_WZ4nGn4Le",
        "colab_type": "text"
      },
      "source": [
        "#### Visualising some images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbIrkspCimn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "560240d6-125c-4e71-feb1-67fdf9fa5a29"
      },
      "source": [
        "a = next(iter(train_loader))\n",
        "a[0].size()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBNkbMfirMD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "a236f93c-99ca-4f66-c70f-31ace4dcf372"
      },
      "source": [
        "image, label = next(iter(train_data))\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "print(label)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU3mDtDgoD89",
        "colab_type": "text"
      },
      "source": [
        "### Defining out basic neural network of two linear layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iatpJ6RRivO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FashionNN(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(FashionNN, self).__init__()\n",
        "      input_dim, hidden1, output_dim = 784, 100, 10\n",
        "      self.fc1 = nn.Linear(input_dim, hidden1) \n",
        "      self.fc2 = nn.Linear(hidden1, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.fc1(x)\n",
        "      x = self.fc2(x)\n",
        "      x=x.view(x.size(0),-1)\n",
        "      return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwM-3WwPoKJ1",
        "colab_type": "text"
      },
      "source": [
        "#### Using CrossEntropyLoss()\n",
        "#### Using Adam optimizer for optimization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnhqKitci-G3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "65ace6ec-da85-4b14-f419-cfd456a06351"
      },
      "source": [
        "model = FashionNN()\n",
        "\n",
        "error = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "print(model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionNN(\n",
            "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0l3-yYFpHz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a4c8fe41-63a9-44aa-83d8-0a7e69f58199"
      },
      "source": [
        "model.to(\"cpu\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionNN(\n",
              "  (fc1): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A13_ROLxobWm",
        "colab_type": "text"
      },
      "source": [
        "### Training and testing our model with the dataset we genereated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHpldI9rfp5O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6a8a3360-df72-4ee3-fb48-b1fed1071e79"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for images, labels in train_loader:\n",
        "    images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
        "    train = images.reshape(images.size(0),-1)\n",
        "    labels = Variable(labels)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(train)\n",
        "    loss = error(outputs, labels)\n",
        "    # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    #Propagating the error backward\n",
        "    loss.backward()\n",
        "    # Optimizing the parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    count += 1\n",
        "    \n",
        "# Testing the model\n",
        "    \n",
        "    if not (count % 50):\n",
        "       total = 0\n",
        "       correct = 0\n",
        "       for images, labels in test_loader:\n",
        "         images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
        "         labels_list.append(labels)\n",
        "         test = images.reshape(images.size(0),-1)\n",
        "         \n",
        "         outputs = model(test)\n",
        "            \n",
        "         predictions = torch.max(outputs, 1)[1].to(\"cpu\")\n",
        "         predictions_list.append(predictions)\n",
        "         correct += (predictions == labels).sum()\n",
        "            \n",
        "         total += len(labels)\n",
        "            \n",
        "         accuracy = correct * 100 / total\n",
        "         loss_list.append(loss.data)\n",
        "         iteration_list.append(count)\n",
        "         accuracy_list.append(accuracy)\n",
        "        \n",
        "    if not (count % 500):\n",
        "      print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 500, Loss: 0.6590723395347595, Accuracy: 83%\n",
            "Iteration: 1000, Loss: 0.5087959170341492, Accuracy: 83%\n",
            "Iteration: 1500, Loss: 0.3736205995082855, Accuracy: 82%\n",
            "Iteration: 2000, Loss: 0.48350393772125244, Accuracy: 83%\n",
            "Iteration: 2500, Loss: 0.3349127471446991, Accuracy: 83%\n",
            "Iteration: 3000, Loss: 0.36228999495506287, Accuracy: 84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFgc_JPis3AT",
        "colab_type": "text"
      },
      "source": [
        "### Printing the confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBFAqOWOsYUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain \n",
        "\n",
        "predictions_l = [predictions_list[i].tolist() for i in range(len(predictions_list))]\n",
        "labels_l = [labels_list[i].tolist() for i in range(len(labels_list))]\n",
        "predictions_l = list(chain.from_iterable(predictions_l))\n",
        "labels_l = list(chain.from_iterable(labels_l))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbWV2SEjsm-5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "38949017-e871-4eda-de8f-b5bcc1ad5d23"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "confusion_matrix(labels_l, predictions_l)\n",
        "print(\"Classification report for CNN :\\n%s\\n\"\n",
        "      % (metrics.classification_report(labels_l, predictions_l)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report for CNN :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79     60000\n",
            "           1       0.96      0.95      0.96     60000\n",
            "           2       0.70      0.72      0.71     60000\n",
            "           3       0.81      0.86      0.84     60000\n",
            "           4       0.71      0.73      0.72     60000\n",
            "           5       0.94      0.90      0.92     60000\n",
            "           6       0.60      0.54      0.57     60000\n",
            "           7       0.89      0.92      0.91     60000\n",
            "           8       0.93      0.95      0.94     60000\n",
            "           9       0.92      0.94      0.93     60000\n",
            "\n",
            "    accuracy                           0.83    600000\n",
            "   macro avg       0.83      0.83      0.83    600000\n",
            "weighted avg       0.83      0.83      0.83    600000\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWBUOFl6sqer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}